import cv2
import mediapipe as mp
import numpy as np
import pandas as pd
import os
from scipy.spatial import distance as dist
from tqdm import tqdm  # é€²åº¦æ¢
from pathlib import Path
from mediapipe.python._framework_bindings import resource_util

# =======================================================
# 0. MediaPipe è³‡æºè·¯å¾‘è™•ç†ï¼ˆä½ åŸæœ¬çš„è¨­å®šä¿ç•™ï¼‰
# =======================================================
DEFAULT_RESOURCE_DIR = Path(mp.__file__).resolve().parent.parent  # site-packages
FALLBACK_RESOURCE_DIR = Path("C:/mp_resources")
RESOURCE_DIR = FALLBACK_RESOURCE_DIR if (FALLBACK_RESOURCE_DIR / "mediapipe").exists() else DEFAULT_RESOURCE_DIR
_set_dir = resource_util.set_resource_dir
resource_util.set_resource_dir = lambda *_args, **_kwargs: _set_dir(str(RESOURCE_DIR))  # override to force ASCII-safe path
resource_util.set_resource_dir(str(RESOURCE_DIR))

# =======================================================
# 1. è·¯å¾‘èˆ‡ã€Œæ¯é¡æœ€å¤šè™•ç†å¼µæ•¸ã€è¨­å®š
# =======================================================
DATASETS = {
    "drowsy": "data/drowsy",
    "notdrowsy": "data/notdrowsy"
}

# â˜… æ¯ä¸€é¡æœ€å¤šè™•ç†å¹¾å¼µåœ–ï¼ˆå¯ä»¥ä¾éœ€æ±‚èª¿æ•´ï¼‰
MAX_PER_CLASS = 5000   # æƒ³è¦å…¨è·‘å°±æ”¹æˆ None æˆ–å¾ˆå¤§çš„æ•¸å­—


# =======================================================
# 2. MediaPipe FaceMesh è¨­å®šï¼ˆæ”¹æˆæ¯”è¼ƒå¿«çš„ç‰ˆæœ¬ï¼‰
# =======================================================
mp_face_mesh = mp.solutions.face_mesh

graph_override = FALLBACK_RESOURCE_DIR / "mediapipe/modules/face_landmark/face_landmark_front_cpu.binarypb"
if graph_override.exists():
    mp_face_mesh._BINARYPB_FILE_PATH = str(graph_override)

# â˜… é—œæ‰ refine_landmarksï¼ŒåŠ é€Ÿæ¨è«–
face_mesh = mp_face_mesh.FaceMesh(
    static_image_mode=True,          # è™•ç†éœæ…‹åœ–ç‰‡
    max_num_faces=1,
    refine_landmarks=False,          # â˜… é—œæ‰é«˜ç²¾åº¦ç´°ç¯€ â†’ é€Ÿåº¦å¤§å¹…æå‡
    min_detection_confidence=0.5
)

# =======================================================
# 3. é—œéµé»ç´¢å¼• & EAR / MAR è¨ˆç®—
# =======================================================
LEFT_EYE = [362, 385, 387, 263, 373, 380]
RIGHT_EYE = [33, 160, 158, 133, 153, 144]
MOUTH = [78, 81, 13, 311, 308, 402, 14, 178]
POSE_POINTS = [33, 263, 1, 61, 291, 199]

def calculate_ear(eye_points, landmarks):
    p = [landmarks[i] for i in eye_points]
    A = dist.euclidean((p[1].x, p[1].y), (p[5].x, p[5].y))
    B = dist.euclidean((p[2].x, p[2].y), (p[4].x, p[4].y))
    C = dist.euclidean((p[0].x, p[0].y), (p[3].x, p[3].y))
    return (A + B) / (2.0 * C) if C != 0 else 0

def calculate_mar(mouth_points, landmarks):
    p = [landmarks[i] for i in mouth_points]
    A = dist.euclidean((p[1].x, p[1].y), (p[7].x, p[7].y))
    B = dist.euclidean((p[2].x, p[2].y), (p[6].x, p[6].y))
    C = dist.euclidean((p[3].x, p[3].y), (p[5].x, p[5].y))
    D = dist.euclidean((p[0].x, p[0].y), (p[4].x, p[4].y))
    return (A + B + C) / (2.0 * D) if D != 0 else 0

data_list = []

print("ğŸš€ é–‹å§‹è™•ç†å…©å€‹è³‡æ–™é›†ï¼Œé€™å¯èƒ½éœ€è¦å¹¾åˆ†é˜...")

# =======================================================
# 4. ä¸»è¿´åœˆï¼šé€é¡åˆ¥è™•ç†åœ–ç‰‡
# =======================================================
for label_name, folder_path in DATASETS.items():
    label = 1 if label_name == "drowsy" else 0

    if not os.path.exists(folder_path):
        print(f"âš ï¸ è·³éï¼šæ‰¾ä¸åˆ°è·¯å¾‘ {folder_path}")
        continue

    files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]

    # â˜… å¦‚æœæœ‰è¨­å®š MAX_PER_CLASSï¼Œå°±åªå–å‰ N å¼µ
    if MAX_PER_CLASS is not None:
        files = files[:MAX_PER_CLASS]

    print(f"æ­£åœ¨è™•ç† {label_name} (é€™æ¬¡å¯¦éš›è™•ç† {len(files)} å¼µ)...")

    # tqdm é¡¯ç¤ºé€²åº¦æ¢
    for filename in tqdm(files):
        filepath = os.path.join(folder_path, filename)
        image = cv2.imread(filepath)
        if image is None:
            continue

        # â˜… å¯é¸ï¼šè‹¥åœ–ç‰‡å¤ªå¤§ï¼Œå…ˆç¸®å°ä»¥åŠ é€Ÿï¼ˆæœƒæ›´å¿«ï¼‰
        h, w = image.shape[:2]
        if max(h, w) > 720:  # ä¾‹å¦‚æœ€å¤§é‚Šé™åˆ¶åœ¨ 720
            scale = 720 / max(h, w)
            new_size = (int(w * scale), int(h * scale))
            image = cv2.resize(image, new_size)

        # FaceMesh è¦åƒ RGB
        results = face_mesh.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

        if results.multi_face_landmarks:
            landmarks = results.multi_face_landmarks[0].landmark

            ear_left = calculate_ear(LEFT_EYE, landmarks)
            ear_right = calculate_ear(RIGHT_EYE, landmarks)
            mar = calculate_mar(MOUTH, landmarks)

            # Head pose (pitch, yaw, roll)
            face_2d, face_3d = [], []
            for idx in POSE_POINTS:
                lm = landmarks[idx]
                x, y = int(lm.x * w), int(lm.y * h)
                face_2d.append([x, y])
                face_3d.append([x, y, lm.z])

            face_2d = np.array(face_2d, dtype=np.float64)
            face_3d = np.array(face_3d, dtype=np.float64)

            cam_matrix = np.array([[w, 0, h / 2],
                                   [0, w, w / 2],
                                   [0, 0, 1]], dtype=np.float64)
            dist_matrix = np.zeros((4, 1), dtype=np.float64)

            pitch = yaw = roll = 0.0
            try:
                success, rot_vec, _ = cv2.solvePnP(
                    face_3d, face_2d, cam_matrix, dist_matrix, flags=cv2.SOLVEPNP_ITERATIVE
                )
                if success:
                    rmat, _ = cv2.Rodrigues(rot_vec)
                    angles, *_ = cv2.RQDecomp3x3(rmat)
                    pitch = angles[0] * 360
                    yaw = angles[1] * 360
                    roll = angles[2] * 360
            except Exception:
                pitch = yaw = roll = 0.0

            data_list.append([ear_left, ear_right, mar, pitch, yaw, roll, label])

# =======================================================
# 5. å­˜æˆ CSV
# =======================================================
df = pd.DataFrame(data_list, columns=['ear_left', 'ear_right', 'mar', 'pitch', 'yaw', 'roll', 'label'])
df.to_csv('training_data.csv', index=False, encoding='utf-8-sig')
print(f"âœ… è™•ç†å®Œæˆï¼å…±æå– {len(df)} ç­†æœ‰æ•ˆè³‡æ–™ï¼Œå·²å­˜ç‚º training_data.csv")
