ä¸€ã€è·Ÿä½ æ–¹å‘æœ€æ¥è¿‘çš„ã€ŒMediaPipe / FaceMeshã€æ–‡ç»èˆ‡å°ˆæ¡ˆ

é€™äº›æ˜¯çœŸçš„æœ‰ç”¨ MediaPipe FaceMesh æˆ–é¡ä¼¼ landmarkï¼‹EAR/PERCLOS çš„ç³»çµ±ï¼Œå¯ä»¥ç›´æ¥åœ¨ä½ çš„æœŸæœ«å ±å‘Šã€è«–æ–‡è£¡å¼•ç”¨ï¼š

1. ç”¨ MediaPipe + EAR çš„å¯¦ä½œæ•™å­¸èˆ‡ç¯„ä¾‹

LearnOpenCV â€“ Driver Drowsiness Detection Using MediaPipe in Pythonï¼ˆ2022ï¼‰

ç”¨ MediaPipe FaceMesh å– 468 é»ï¼Œé¸ 12 å€‹çœ¼ç› landmark è¨ˆç®— EARã€‚

è¨­å®š EAR é–€æª»ï¼‹é€£çºŒé–‰çœ¼å¹€æ•¸ä¾†åˆ¤å®šç–²å‹ï¼Œä¸¦ä¸”åšåˆ° Streamlit å³æ™‚ Web appã€‚
learnopencv.com

Doc Zamora â€“ Mediapipe Drowsy Driver Detectionï¼ˆBlogï¼‰

è©³ç´°è¬›è§£ FaceMesh pipelineã€çœ¼ç›å€åŸŸé¸é»èˆ‡ EAR çš„è¨ˆç®—ï¼Œä»¥åŠå¦‚ä½•åœ¨å½±åƒä¸²æµä¸­åš real-time åµæ¸¬ã€‚
doczamora.com

RidgeRun â€“ Using PERCLOS for Effective Driver Drowsiness Detection

ä½¿ç”¨ MediaPipe çœ¼ç›å°‘æ•¸ landmarkï¼ˆ145,159,374,386ï¼‰ï¼Œåªçœ‹å‚ç›´è·é›¢è®ŠåŒ–ä¾†ä¼°è¨ˆé–‰çœ¼æ¯”ä¾‹ï¼Œé€²è€Œè¨ˆç®— PERCLOSã€‚

GitHub â€“ Driver Monitoring System using MediaPipe FaceMesh

å®Œæ•´ DMS å°ˆæ¡ˆï¼Œç”¨ MediaPipe FaceMesh è¨ˆç®— EAR + PERCLOSï¼Œæä¾›å³æ™‚ç–²å‹èˆ‡åˆ†å¿ƒæé†’ã€‚
GitHub

GitHub â€“ Driver-Drowsiness-detection-using-Mediapipeï¼ˆSaiVishwa021ï¼‰

ç”¨ MediaPipe FaceMeshï¼‹EARï¼Œå¼·èª¿ã€ŒæŒçºŒé–‰çœ¼ã€è€Œéä¸€èˆ¬çœ¨çœ¼ï¼Œé¡ä¼¼ä½ æƒ³åšçš„ã€Œæ™‚é–“çª—ç´¯ç©æŒ‡æ¨™ã€ã€‚
GitHub

2. æ˜è¬›ã€Œä½¿ç”¨ MediaPipe FaceMeshã€çš„å­¸è¡“è«–æ–‡

Drowsy Alarm System Based on Face Landmarks Detection Using MediaPipeï¼ˆSpringer 2021 å·¦å³ï¼‰

ç›´æ¥å¯«æ˜ï¼šç”¨ MediaPipe FaceMeshï¼ˆ486 å€‹ 3D landmarkï¼‰åµæ¸¬çœ¼ç›é–‰åˆèˆ‡å“ˆæ¬ ï¼Œå‰ç«¯ç”¨ TensorFlow.js åœ¨ç€è¦½å™¨å³æ™‚åŸ·è¡Œã€‚
springerprofessional.de

Development of a Real-time Driverâ€™s Drowsiness Detection System Using MediaPipe Face Meshï¼ˆIJEM, 2025ï¼‰

ä»¥ MediaPipe FaceMesh åšå³æ™‚ç–²å‹åµæ¸¬ï¼Œèšç„¦åœ¨çœ¼ç›é–‰åˆèˆ‡çœ¨çœ¼æ¨¡å¼ï¼Œè­‰æ˜åœ¨ä¸€èˆ¬æ”å½±æ©Ÿç¡¬é«”ä¸Šä¹Ÿèƒ½é”åˆ° real-timeã€‚
SSRN

IJERT â€“ Drowsy Driver Detection System Using Deep Learningï¼ˆ2023ï¼‰

ç³»çµ±å‰ç«¯ç”¨ MediaPipe FaceMesh åš landmark trackingï¼Œå†é€å…¥æ·±åº¦å­¸ç¿’åšé ­éƒ¨å§¿æ…‹èˆ‡ç–²å‹ç‹€æ…‹æ¨è«–ã€‚
IJERT

Design of a System for Driver Drowsiness Detection and Seat Belt Useï¼ˆåœ–ä¸­ç¤º MediaPipe FaceMeshï¼‰

è«–æ–‡ä¸­ç›´æ¥ç”¨ FaceMesh åœ–ç¤º 468 é»ï¼Œé¡¯ç¤ºä»¥ MediaPipe landmark ä½œç‚º fatigue indicator çš„ä¾æ“šã€‚
ResearchGate

3. æ²’æœ‰ MediaPipe ä½†æ¦‚å¿µå®Œå…¨ç›¸åŒçš„ã€ŒFacial Landmark + EAR/PERCLOSã€ç¶“å…¸é¡å‹

Hybrid Facial Features + Ensembleï¼ˆXu et al., Information 2025ï¼‰

ç”¨çœ¼ç›ã€å˜´å·´è¼ªå»“ã€é ­éƒ¨å§¿æ…‹ã€è¦–ç·šæ–¹å‘ç­‰å¤šç¨®è¦–è¦ºç‰¹å¾µï¼Œæ­é… RFï¼‹XGBoostï¼‹MLP çš„æŠ•ç¥¨ ensembleï¼Œæå‡ç–²å‹è¾¨è­˜æº–ç¢ºåº¦ã€‚
MDPI

å¤šç¯‡ 2021â€“2024 çš„ç¶œè¿°ï¼ˆSurvey on Drowsiness Detectionï¼‰

æŒ‡å‡ºå¤§å¤š vision-based ç³»çµ±ä»¥è‡‰éƒ¨è¡¨æƒ…ã€é ­éƒ¨å§¿æ…‹ã€çœ¼ç›é–‹é–‰èˆ‡ PERCLOS ç‚ºä¸»è¦ç‰¹å¾µï¼Œä¸¦ä½¿ç”¨ rule-based æˆ–æ©Ÿå™¨å­¸ç¿’åšåˆ†é¡ã€‚
arXiv
+1

æœ€æ–°æ·±åº¦å­¸ç¿’æ¶æ§‹ï¼ˆHassan et al., 2025, Transformer-based Drowsiness Detectionï¼‰

ç”¨ Transformer + transfer learning åš real-time æ¬Šè¡¡ï¼Œä½œç‚ºä½ æœªä¾†è¦å°æ¯”çš„é«˜éš baselineã€‚
Nature

ä½ åœ¨å ±å‘Šè£¡å¯ä»¥åˆ†å…©é¡å¯«ï¼š

ã€Œå‚³çµ± facial landmark-basedï¼ˆå¯ç”¨ MediaPipe å¯¦ç¾ï¼‰ã€

ã€Œç«¯åˆ°ç«¯æ·±åº¦å­¸ç¿’ï¼ˆCNN / Transformerï¼‰ã€
ç„¶å¾Œèªªï¼šæˆ‘å€‘é¸æ“‡ MediaPipeï¼‹ç‰¹å¾µå·¥ç¨‹ï¼‹è¼•é‡ MLï¼Œå…¼é¡§å³æ™‚æ€§èˆ‡å¯è§£é‡‹æ€§ã€‚

äºŒã€å¾é€™äº›æ–‡ç»ä¸­æŠ½å‡ºã€Œå³æ™‚ + æº–ç¢ºã€çš„é—œéµåšæ³•

æ­¸ç´ä¸Šé¢ MediaPipe/landmark çš„ç³»çµ±ï¼Œå…¶å¯¦å¤§å¤šéƒ½éµå®ˆå¹¾å€‹å…±åŒåŸå‰‡ã€‚ä½ åªè¦ç…§é€™å¹¾æ¢è¨­è¨ˆï¼Œä½ çš„ç³»çµ±å°±æœƒçœ‹èµ·ä¾†å¾ˆã€Œpaper-gradeã€ã€‚

1. MediaPipe FaceMesh ä½¿ç”¨è¨­å®šèˆ‡æ•ˆèƒ½

è¨­å®šå»ºè­°ï¼š

mp_face_mesh.FaceMesh(
    static_image_mode=False,         # ä¸€å®šè¦ Falseï¼šè®“ tracking ç™¼æ®åŠ é€Ÿæ•ˆæœ
    max_num_faces=1,                 # è»Šå…§åªæœ‰ä¸€å€‹é§•é§›
    refine_landmarks=True,           # éœ€è¦æ›´æº–çš„çœ¼ç›èˆ‡å˜´å·´é»
    min_detection_confidence=0.5,
    min_tracking_confidence=0.5
)


static_image_mode=False èƒ½è®“ç¬¬ 2 å¹€ä¹‹å¾Œç”¨ tracking çœæ™‚é–“ï¼Œæ–‡ç»ä¹Ÿå¤šå¼·èª¿ real-time è¦é  trackingã€‚
learnopencv.com
+1

resolution å»ºè­° 640Ã—480 or 720p ä»¥ä¸‹ï¼Œæ–‡ç»èˆ‡æ•™å­¸å¯¦ä½œéƒ½æŒ‡å‡ºé€™æ¨£åœ¨ CPU ä¸Šä¹Ÿèƒ½ç¶­æŒ 20â€“30 FPSã€‚
learnopencv.com

2. ç²¾æº–åµæ¸¬çš„æ ¸å¿ƒï¼šç‰¹å¾µä¸æ˜¯åªæœ‰ EAR

æ–‡ç»ä¸­æ™®éç™¼ç¾ï¼Œå–®çœ‹ EAR å®¹æ˜“å°å€‹é«”èˆ‡å…‰ç·šæ•æ„Ÿï¼Œæ‰€ä»¥é«˜æº–ç¢ºç‡çš„ç ”ç©¶éƒ½æœƒåŠ ä¸Šæ›´å¤šè¡Œç‚ºç‰¹å¾µï¼š
arXiv
+2
MDPI
+2

ä½ å¯ä»¥åšçš„çµ„åˆï¼š

çœ¼ç›ç›¸é—œ

å³æ™‚ EARï¼ˆå·¦å³çœ¼ï¼‹å¹³å‡ï¼‰

PERCLOSï¼šåœ¨ 30 ç§’å…§é–‰çœ¼çš„ frame æ¯”ä¾‹

çœ¨çœ¼é »ç‡ / å¹³å‡ blink duration

å˜´å·´ç›¸é—œ

MARï¼ˆMouth Aspect Ratioï¼‰ï¼šåˆ©ç”¨å˜´å·´ä¸Šä¸‹ vs å·¦å³è·é›¢

POMï¼ˆPercentage of Mouth Opennessï¼‰â†’ 2025 å¹´æœ‰ paper å°ˆé–€ç”¨é€™å€‹åš fatigue æª¢æ¸¬ã€‚
scitepress.org

é ­éƒ¨å§¿æ…‹ / åˆ†å¿ƒ

ç”¨é¼»å°–ï¼‹çœ¼ç›ï¼‹è€³æœµç­‰é»ä¼°è¨ˆ pitch/yaw/roll

æŒçºŒåé ­æˆ–ä½é ­ä¹Ÿå¯è¦–ç‚º fatigue / distraction æŒ‡æ¨™
IJERT
+1

æ™‚é–“çª—çµ±è¨ˆç‰¹å¾µ

åœ¨ 1â€“3 ç§’ / 10â€“30 ç§’çª—å…§è¨ˆç®—ï¼š

EAR/MAR çš„å¹³å‡ã€è®Šç•°ã€æœ€å°å€¼

é–‰çœ¼æ¬¡æ•¸ã€å“ˆæ¬ æ¬¡æ•¸

å¾ˆå¤šå¯¦ä½œï¼ˆLearnOpenCVã€GitHub DMS å°ˆæ¡ˆï¼‰éƒ½æ˜¯ã€Œç‰¹å¾µ + sliding window åˆ¤æ–·ã€ã€‚
learnopencv.com
+1

å¯¦å‹™å»ºè­°ï¼š

ä½ å¯ä»¥æŠŠã€Œå–®å¹€çš„ EAR/MAR + æ™‚é–“çª—çµ±è¨ˆã€ä¸€èµ·é¤µçµ¦ XGBoost / RFï¼›

é€™æ¨£ä¸æœƒå¤ªé‡ï¼Œåˆæ¯”å–®ç´”é–¾å€¼æ³•æ›´ robustã€‚

3. åˆ¤æ–·é‚è¼¯ï¼šä¸è¦åªçœ‹ä¸€å¹€ï¼Œè¦çœ‹ã€Œæ™‚é–“ã€

å¹¾ä¹æ‰€æœ‰è«–æ–‡èˆ‡å¯¦ä½œéƒ½æœƒå¼·èª¿ï¼š

ç–²å‹ â‰  ä¸€å¹€é–‰çœ¼ï¼Œè€Œæ˜¯ã€Œé•·æ™‚é–“é–‰çœ¼ã€ï¼‹ã€Œçœ¨çœ¼è®Šæ…¢ã€ï¼‹ã€Œæ‰“å“ˆæ¬ é »ç‡ä¸Šå‡ã€ã€‚
learnopencv.com
+2
scitepress.org
+2

ä½ å¯ä»¥åƒè€ƒå¸¸è¦‹è¨­è¨ˆï¼š

çŸ­æ™‚é–“çª—ï¼ˆ0.5â€“2 ç§’ï¼‰

EAR é€£çºŒä½æ–¼ thresholdï¼ˆä¾‹å¦‚ <0.18ï¼‰è¶…é N å¹€ â†’ è¦–ç‚ºã€Œä¸€æ¬¡é•·é–‰çœ¼ã€äº‹ä»¶ã€‚

ä¸­æ™‚é–“çª—ï¼ˆ30 ç§’ï¼‰

PERCLOS > 0.3 â†’ ç–²å‹é¢¨éšªé«˜

çœ¨çœ¼é »ç‡æ¯”å€‹äºº baseline å¤§å¹…ä¸‹é™

æ¨¡å‹è¼¸å…¥ï¼š

åšæˆ feature vectorï¼Œä¾‹å¦‚ï¼š

ear_avg, ear_min, perclos_30s, blink_rate_30s, mar_max_10s, head_pitch_mean, head_yaw_std

ä¸Ÿé€² XGBoost / RF / å° MLP åšåˆ†é¡ï¼ˆnormal / drowsy / very_drowsyï¼‰

é€™ç¨®ã€Œç‰¹å¾µï¼‹æ™‚é–“çª—ã€çš„è¨­è¨ˆï¼Œåœ¨ Xu 2025 çš„ hybrid feature paper èˆ‡å¤šç¯‡ survey éƒ½è¢«èªç‚ºæ˜¯å¾ˆæœ‰æ•ˆçš„æŠ˜è¡·æ–¹æ¡ˆã€‚
MDPI
+2
arXiv
+2

4. é–¾å€¼è¨­å®šï¼šå›ºå®š vs è‡ªé©æ‡‰ï¼ˆper-user/adaptiveï¼‰

æ–‡ç»ä¸­æœ‰å…©å¤§æµæ´¾ï¼š

å›ºå®šé–¾å€¼ï¼ˆç°¡å–®å¥½å¯¦ä½œï¼‰

EAR é–¾å€¼å¤šåœ¨ 0.15â€“0.25 ä¹‹é–“ï¼Œæœƒä¾ç›¸æ©Ÿ/æ—ç¾¤ä¸åŒè€Œå¾®èª¿ã€‚
learnopencv.com
+1

PERCLOS é–¾å€¼ç´„ 0.3â€“0.4ã€‚

å‹•æ…‹/è‡ªé©æ‡‰é–¾å€¼

ç³»çµ±å…ˆç”¨å‰å¹¾åç§’ã€Œæ¸…é†’ç‹€æ…‹ã€ä¼°è¨ˆå€‹äºº baseline EAR/MARï¼Œä¹‹å¾Œç”¨

EAR_threshold = baseline_EAR - k * std(EAR)

å¯æ¸›å°‘ä¸åŒäººçœ¼å‹ / æˆ´çœ¼é¡çš„å½±éŸ¿ã€‚

ğŸ‘‰ å»ºè­°ä½ åœ¨è«–æ–‡/ç°¡å ±è£¡å¯«ï¼š

æˆ‘å€‘æ··åˆä½¿ç”¨ã€Œå€‹äººåŒ– adaptive threshold + XGBoostã€ï¼Œä½¿ç³»çµ±å°ä¸åŒé§•é§›çœ¼å‹ã€å…‰ç·šæ¢ä»¶æ›´ç©©å¥ã€‚

5. å³æ™‚æ€§ï¼šFps & å»¶é²çš„åšæ³•

å¹¾å€‹å¯¦ä½œèˆ‡è«–æ–‡çš„å…±é€šé»ï¼š
learnopencv.com
+2
IJERT
+2

é™è§£æåº¦ï¼šè¼¸å…¥ 640Ã—480 æˆ– 320Ã—240ï¼›

é™åˆ¶ FaceMesh é »ç‡ï¼šä¾‹å¦‚ 15 FPS å°±å¤ ï¼Œä¸ä¸€å®šè¦å…¨é€Ÿï¼›

éå¿…è¦ä¸åš heavy CNNï¼š

ä½ çš„ pipeline å¯ä»¥æ˜¯ï¼š

FaceMeshï¼ˆGPU/CPUï¼‰

è¨ˆç®—ç‰¹å¾µï¼ˆNumpy å‘é‡é‹ç®—ï¼‰

XGBoost æ¨è«–ï¼ˆæ¥µå¿«ï¼‰

ç•°æ­¥è™•ç†ï¼ˆoptional é€²éšï¼‰ï¼š

ä¸€å€‹ Thread è®€å–å½±åƒ + FaceMesh

å¦ä¸€å€‹ Thread åšç‰¹å¾µå¹³æ»‘ï¼‹æ¨¡å‹æ¨è«–ï¼‹UI é¡¯ç¤º

åœ¨ä½ çš„æœŸæœ«å°ˆé¡Œç¨‹åº¦ï¼Œåªè¦åšåˆ°ï¼š

å–®æ©Ÿ CPU ä¸Šç¶­æŒ 15â€“20 FPSï¼›

ç•«é¢ä¸Šé¡¯ç¤º EAR / PERCLOS / ç›®å‰ç­‰ç´šï¼ˆNormal / Drowsyï¼‰ï¼›

å°±å·²ç¶“å¯ä»¥å¯«æˆã€Œreal-timeã€äº†ã€‚

6. è³‡æ–™èˆ‡æ³›åŒ–ï¼šè¦å¤šè³‡æ–™é›† + cross-dataset

è¼ƒæ–°çš„ç ”ç©¶æœƒå¼·èª¿ï¼šä¸è¦åªåœ¨ä¸€å€‹è³‡æ–™é›†ä¸Šæ¸¬è©¦ã€‚
MDPI
+2
Nature
+2

ä½ å¯ä»¥å¯«ï¼š

è¨“ç·´ï¼šNTHU-DDD2 + è‡ªéŒ„å½±ç‰‡

æ¸¬è©¦ï¼šUTA-RLDD / D3S / SUST-DDD å…¶ä¸­ä¹‹ä¸€

æŒ‡æ¨™ï¼šAccuracy, F1, AUC, ä»¥åŠ False Alarm Rate

1. ç¢ºä¿ã€Œå³æ™‚æ€§ã€ (Real-time)
ä¸è¦å°‡æ•´å¼µåœ–ç‰‡ä¸Ÿé€²å»è¨“ç·´ï¼Œè€Œæ˜¯åªã€Œèƒå–æ•¸å€¼ã€ã€‚


ç­–ç•¥ï¼šMediaPipe + ç‰¹å¾µå·¥ç¨‹ + è¼•é‡å­¸ç¿’å™¨ ã€‚


åŸå› ï¼š


MediaPipe Face Meshï¼šå¯ä»¥ç›´æ¥åœ¨ CPU ä¸Šä»¥æ¥µå¿«é€Ÿåº¦ (å¯é” <5ms å»¶é²) è¼¸å‡º 468 å€‹é—œéµé»ï¼Œç„¡éœ€ GPU ã€‚



ç¹é CNNï¼šå‚³çµ± CNN æ–¹æ³• (å¦‚ ResNet) éœ€è¦å¤§é‡çš„çŸ©é™£é‹ç®—ï¼Œè€Œæ”¹ç”¨ XGBoost/RandomForest ç­‰ã€Œæ¨¹æ¨¡å‹ã€ï¼Œé‹ç®—é‡æ¥µä½ï¼Œé©åˆå¯¦æ™‚éƒ¨ç½² ã€‚



è³‡æ–™æ•ˆç‡ï¼šXGBoost ç­‰æ¨¡å‹å°è¨“ç·´è³‡æ–™é‡çš„éœ€æ±‚é ä½æ–¼ç«¯åˆ°ç«¯çš„æ·±åº¦å­¸ç¿’æ¨¡å‹ ã€‚

2. ç¢ºä¿ã€Œæº–ç¢ºæ€§ã€ (Accuracy)
å–®é ã€Œçœ¼ç›é–‹åˆã€å®¹æ˜“èª¤åˆ¤ (ä¾‹å¦‚å–®ç´”çœ¨çœ¼)ï¼Œå¿…é ˆæ¡ç”¨å¤šç‰¹å¾µèåˆ (Multi-feature Fusion)ã€‚


èåˆç‰¹å¾µå‘é‡ï¼šæ‚¨çš„è¼¸å…¥è³‡æ–™ä¸æ‡‰åªæœ‰ EARï¼Œå¿…é ˆåŒ…å«ä»¥ä¸‹å¤šç¶­åº¦ç‰¹å¾µ ï¼š





EAR (Eye Aspect Ratio)ï¼šåˆ¤æ–·çœ¼ç›é–‰åˆ ã€‚



PERCLOSï¼šè¨ˆç®—ä¸€æ®µæ™‚é–“å…§é–‰çœ¼çš„ä½”æ¯”ï¼Œé€™æ˜¯æ¯”å–®ç´”é–‰çœ¼æ›´æº–ç¢ºçš„ç–²å‹æŒ‡æ¨™ ã€‚





MAR (Mouth Aspect Ratio)ï¼šåˆ¤æ–·æ˜¯å¦åœ¨æ‰“å“ˆæ¬  ã€‚






Head Pose (Pitch/Yaw/Roll)ï¼šåˆ¤æ–·æ˜¯å¦é»é ­çŒç¡æˆ–è½‰é ­åˆ†å¿ƒ ã€‚





é›†æˆå­¸ç¿’ (Ensemble Learning)ï¼š

ä½¿ç”¨ XGBoost æˆ– RandomForestã€‚é€™äº›æ¨¡å‹ç”±å¤šæ£µæ±ºç­–æ¨¹çµ„æˆï¼Œæ¯”å–®ä¸€é‚è¼¯å›æ­¸ (Logistic Regression) æ›´èƒ½æ•æ‰ç‰¹å¾µä¹‹é–“çš„éç·šæ€§é—œä¿‚ (ä¾‹å¦‚ï¼šé›–ç„¶çœ¼ç›å¼µé–‹ï¼Œä½†é ­ä¸€ç›´é »ç¹é»å‹• = ç–²å‹) ã€‚



ä¸‰ã€ ç¸½çµèˆ‡å»ºè­°
æ‚¨çš„å°ˆæ¡ˆæ–¹å‘ ã€ŒMediaPipe + XGBoostã€ å®Œå…¨ç¬¦åˆ 2020 å¹´å¾Œè¼•é‡åŒ–é‚Šç·£é‹ç®—çš„ç ”ç©¶è¶¨å‹¢ ã€‚

å»ºè­°å¯¦ä½œæ­¥é©Ÿï¼š

å¼•ç”¨æ–‡ç»ï¼šåœ¨ Introduction å¼•ç”¨ SoukupovÃ¡ (EAR) èˆ‡ Rastgoo (MediaPipeæ‡‰ç”¨) ä¾†å»ºç«‹ç†è«–åŸºç¤ã€‚


ç‰¹å¾µå·¥ç¨‹ï¼šç¨‹å¼ç¢¼ä¸­å‹™å¿…å¯¦ä½œ PERCLOS (è€Œä¸åƒ…åƒ…æ˜¯ EAR)ï¼Œé€™æœƒå¤§å¹…æå‡æº–ç¢ºåº¦ ã€‚


æ¨¡å‹é¸æ“‡ï¼šåœ¨å ±å‘Šä¸­å¼·èª¿é¸æ“‡ XGBoost æ˜¯ç‚ºäº†åœ¨ã€Œæº–ç¢ºåº¦ã€èˆ‡ã€Œéƒ¨ç½²é›£åº¦ã€ä¹‹é–“å–å¾—æœ€ä½³å¹³è¡¡ (Best Trade-off) ã€‚